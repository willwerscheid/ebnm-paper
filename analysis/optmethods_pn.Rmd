---
title: "Testing point-normal optimization methods"
author: "Jason Willwerscheid"
date: "10/28/2020"
output:
  workflowr::wflow_html:
    code_folding: hide
    toc: false
---

```{r setup, include = FALSE}
options(width = 100)
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, comment = "#>")
```

I compare the performance of different optimization methods for solving the EBNM problem with point-normal priors. The "true" prior I've used to generate the data is
$$ \theta_i \sim 0.8 \delta_0 + 0.2 N(0, 2^2) $$
The variance $s_i^2$ for each observation $x_i$ is generated from an exponential distribution with mean 1. I compare `nlm` (with and without supplying gradients and Hessians), `optim` (method `L-BFGS-B` with and without supplying gradients), and `trust`.

Each method uses different convergence criteria: `nlm` checks the "scaled gradient"; L-BFGS-B checks the "projected gradient in the current search direction"; and `trust` looks directly at the objective function. Nonetheless, I set the tolerance parameter for each to the same value to try to make the quality of each solution at least somewhat comparable. I print the difference in optimal log likelihoods below.


```{r code}
library(microbenchmark)
library(ebnm)
library(ggplot2)

test_n <- function(n, mb_times = 100L, seed = 666) {
  set.seed(seed)
  # true g is 0.8 delta_0 + 0.2 N(0, 2^2)
  theta <- rnorm(n, sd = 2)
  theta[rbinom(n, size = 1, prob = 0.8) == 1] <- 0
  s <- sqrt(rexp(n))
  x <- theta + rnorm(n, sd = s)

  test_res <- microbenchmark(
    tres <- ebnm_point_normal(x, s, optmethod = "trust",
                              control = list(fterm = sqrt(.Machine$double.eps))),
    ebnm_point_normal(x, s, optmethod = "nograd_lbfgsb",
                      control = list(control = list(pgtol = sqrt(.Machine$double.eps)))),
    ores <- ebnm_point_normal(x, s, optmethod = "lbfgsb",
                        control = list(control = list(pgtol = sqrt(.Machine$double.eps)))),
    ebnm_point_normal(x, s, optmethod = "nohess_nlm", 
                      control = list(gradtol = sqrt(.Machine$double.eps))),
    ebnm_point_normal(x, s, optmethod = "nograd_nlm", 
                      control = list(gradtol = sqrt(.Machine$double.eps))),
    nres <- ebnm_point_normal(x, s, optmethod = "nlm", 
                        control = list(gradtol = sqrt(.Machine$double.eps))),
    times = mb_times
  )

  levels(test_res$expr) <- c("trust", "L-BFGS-B (no grad)", "L-BFGS-B", 
                          "nlm (no hess)", "nlm (no grad)", "nlm")
  
  llik_res <- c(tres$log_likelihood, ores$log_likelihood, nres$log_likelihood)
  names(llik_res) <- c("trust", "L-BFGS-B", "nlm")
  
  return(list(mb_res = test_res, llik_res = llik_res))
}
```

## n = 1000

Difference from maximum log likelihood among all methods:

```{r n1000}
res1000 <- test_n(1000)
res1000$llik_res - max(res1000$llik_res)
```

Timing results: 

```{r n1000t}
autoplot(res1000$mb_res)
```

## n = 10000

Difference from maximum log likelihood among all methods:

```{r n10000}
res10000 <- test_n(10000)
res10000$llik_res - max(res10000$llik_res)
```

Timing results: 

```{r n10000t}
autoplot(res10000$mb_res)
```

## n = 100000

Difference from maximum log likelihood among all methods:

```{r n100000}
res100000 <- test_n(100000)
res100000$llik_res - max(res100000$llik_res)
```

Timing results: 

```{r n100000t}
autoplot(res100000$mb_res)
```