---
title: "Testing point-normal optimization methods"
author: "Jason Willwerscheid"
date: "10/28/2020"
output:
  workflowr::wflow_html:
    code_folding: hide
    toc: false
---

```{r setup, include = FALSE}
options(width = 100)
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, comment = "#>")
```

I compare the performance of different optimization methods for solving the EBNM problem with point-normal priors. The "true" prior I've used to generate the data is
$$ \theta_i \sim 0.5 \delta_0 + 0.5 N(0, 2^2) $$
The variance $s_i^2$ for each observation $x_i$ is generated from an exponential distribution with mean 1. I compare `nlm` (with and without supplying gradients and Hessians), `optim` (method `L-BFGS-B` with and without supplying gradients), and `trust`.

TODO: Need to choose parameters so that methods are strictly comparable!


```{r code}
library(trust)
library(microbenchmark)

ebnm_pn <- function(x, s, optmethod) {
  return(mle_point_normal(x = x, s = s, g = list(mu = 0), control = list(),
                          fix_pi0 = FALSE, fix_a = FALSE, fix_mu = TRUE,
                          optmethod = optmethod))
}

mle_point_normal <- function(x, s, g, control, fix_pi0, fix_a, fix_mu,
                             optmethod = c("nlm", "nlm_nograd", "lbfgsb", "lbfgsb_wgrad", "trust")) {
  optmethod <- match.arg(optmethod)

  if (!fix_mu && any(s == 0)) {
    stop("The mode cannot be estimated if any SE is zero (the gradient does ",
         "not exist).")
  }

  startpar <- pn_startpar(x, s, g, fix_pi0, fix_a, fix_mu)

  if (fix_pi0) {
    alpha <- -log(1 / g$pi0 - 1)
  } else {
    alpha <- NULL
  }
  if (fix_a) {
    beta <- -log(g$a)
  } else {
    beta <- NULL
  }
  if (fix_mu) {
    mu <- g$mu
  } else {
    mu <- NULL
  }

  if (any(s == 0)) {
    which_s0 <- which(s == 0)
    which_x_nz <- which(x[which_s0] != mu)
    n0 <- length(which_s0) - length(which_x_nz)
    n1 <- length(which_x_nz)
    sum1 <- sum((x[which_s0[which_x_nz]] - mu)^2)
    x <- x[-which_s0]
    s <- s[-which_s0]
  } else {
    n0 <- 0
    n1 <- 0
    sum1 <- 0
  }
  n2 <- length(x)

  s2 <- s^2

  if (fix_mu) {
    z <- (x - mu)^2 / s2
    sum_z <- sum(z)
  } else {
    z <- NULL
    sum_z <- NULL
  }

  if (optmethod == "nlm") {
    optfn <- function(par) {
      pn_nllik(par,
               fix_pi0 = fix_pi0, fix_a = fix_a, fix_mu = fix_mu,
               alpha = alpha, beta = beta, mu = mu,
               n0 = n0, n1 = n1, sum1 = sum1, n2 = n2,
               x = x, s2 = s2, z = z, sum_z = sum_z,
               calc_grad = TRUE, calc_hess = TRUE)
    }
    optres <- nlm(optfn, startpar, ndigit = 8, stepmax = 10, check.analyticals = FALSE)
    retlist <- pn_g_from_optpar(optres$estimate, g, fix_pi0, fix_a, fix_mu)
    retlist$val <- pn_llik_from_optval(optres$minimum, n1, n2, s2)
  } else if (optmethod == "nlm_nograd") {
    optfn <- function(par) {
      pn_nllik(par,
               fix_pi0 = fix_pi0, fix_a = fix_a, fix_mu = fix_mu,
               alpha = alpha, beta = beta, mu = mu,
               n0 = n0, n1 = n1, sum1 = sum1, n2 = n2,
               x = x, s2 = s2, z = z, sum_z = sum_z,
               calc_grad = FALSE, calc_hess = FALSE)
    }
    optres <- nlm(optfn, startpar, ndigit = 8, stepmax = 10)
    retlist <- pn_g_from_optpar(optres$estimate, g, fix_pi0, fix_a, fix_mu)
    retlist$val <- pn_llik_from_optval(optres$minimum, n1, n2, s2)
  } else if (optmethod == "lbfgsb") {
    optfn <- function(par) {
      pn_nllik(par,
               fix_pi0 = fix_pi0, fix_a = fix_a, fix_mu = fix_mu,
               alpha = alpha, beta = beta, mu = mu,
               n0 = n0, n1 = n1, sum1 = sum1, n2 = n2,
               x = x, s2 = s2, z = z, sum_z = sum_z,
               calc_grad = FALSE, calc_hess = FALSE)
    }
    optres <- optim(startpar, optfn, method = "L-BFGS-B")
    retlist <- pn_g_from_optpar(optres$par, g, fix_pi0, fix_a, fix_mu)
    retlist$val <- pn_llik_from_optval(optres$value, n1, n2, s2)
  } else if (optmethod == "lbfgsb_wgrad") {
    optfn <- function(par) {
      pn_nllik(par,
               fix_pi0 = fix_pi0, fix_a = fix_a, fix_mu = fix_mu,
               alpha = alpha, beta = beta, mu = mu,
               n0 = n0, n1 = n1, sum1 = sum1, n2 = n2,
               x = x, s2 = s2, z = z, sum_z = sum_z,
               calc_grad = FALSE, calc_hess = FALSE)
    }
    gradfn <- function(par) {
      nllik <- pn_nllik(par,
                        fix_pi0 = fix_pi0, fix_a = fix_a, fix_mu = fix_mu,
                        alpha = alpha, beta = beta, mu = mu,
                        n0 = n0, n1 = n1, sum1 = sum1, n2 = n2,
                        x = x, s2 = s2, z = z, sum_z = sum_z,
                        calc_grad = TRUE, calc_hess = FALSE)
      return(attr(nllik, "gradient"))
    }
    optres <- optim(startpar, optfn, gr = gradfn, method = "L-BFGS-B")
    retlist <- pn_g_from_optpar(optres$par, g, fix_pi0, fix_a, fix_mu)
    retlist$val <- pn_llik_from_optval(optres$value, n1, n2, s2)
  } else if (optmethod == "trust") {
    optfn <- function(par) {
      nllik <- pn_nllik(par,
                        fix_pi0 = fix_pi0, fix_a = fix_a, fix_mu = fix_mu,
                        alpha = alpha, beta = beta, mu = mu,
                        n0 = n0, n1 = n1, sum1 = sum1, n2 = n2,
                        x = x, s2 = s2, z = z, sum_z = sum_z,
                        calc_grad = TRUE, calc_hess = TRUE)
      return(list(value = nllik,
                  gradient = attr(nllik, "gradient"),
                  hessian = attr(nllik, "hessian")))
    }
    optres <- trust(optfn, startpar, rinit = 1, rmax = 100000)
    retlist <- pn_g_from_optpar(optres$argument, g, fix_pi0, fix_a, fix_mu)
    retlist$val <- pn_llik_from_optval(optres$value, n1, n2, s2)
  }

  return(retlist)
}

# Initial values.
pn_startpar <- function(x, s, g, fix_pi0, fix_a, fix_mu) {
  startpar <- numeric(0)

  if (!fix_pi0) {
    if (!is.null(g$pi0) && g$pi0 > 0 && g$pi0 < 1) {
      startpar <- c(startpar, -log(1 / g$pi0 - 1))
    } else {
      startpar <- c(startpar, 0) # default for logit(pi0)
    }
  }

  if (!fix_a) {
    if (!is.null(g$a)) {
      startpar <- c(startpar, -log(g$a))
    } else {
      startpar <- c(startpar, log(mean(x^2))) # default for -log(a)
    }
  }

  if (!fix_mu) {
    if (!is.null(g$mu)) {
      startpar <- c(startpar, g$mu)
    } else {
      startpar <- c(startpar, mean(x)) # default for mu
    }
  }

  return(startpar)
}

# Pull pi0, a, and mu out of the optimization results.
pn_g_from_optpar <- function(optpar, g, fix_pi0, fix_a, fix_mu) {
  opt_g <- list()

  i <- 1
  if (fix_pi0) {
    opt_g$pi0 <- g$pi0
  } else {
    opt_g$pi0 <- 1 / (exp(-optpar[i]) + 1)
    i <- i + 1
  }

  if (fix_a) {
    opt_g$a <- g$a
  } else {
    opt_g$a <- exp(-optpar[i])
    i <- i + 1
  }

  if (fix_mu) {
    opt_g$mu <- g$mu
  } else {
    opt_g$mu <- optpar[i]
  }

  return(opt_g)
}

pn_llik_from_optval <- function(optval, n1, n2, s2) {
  if (length(s2) == 1) {
    sum.log.s2 <- n2 * log(s2)
  } else {
    sum.log.s2 <- sum(log(s2))
  }
  return(-optval - 0.5 * ((n1 + n2) * log(2 * pi) + sum.log.s2))
}

pn_nllik <- function(par, fix_pi0, fix_a, fix_mu, alpha, beta, mu,
                    n0, n1, sum1, n2, x, s2, z, sum_z,
                    calc_grad = TRUE, calc_hess = TRUE) {
  i <- 1
  if (!fix_pi0) {
    alpha <- par[i]
    i <- i + 1
  }
  if (!fix_a) {
    beta <- par[i]
    i <- i + 1
  }
  if (!fix_mu) {
    mu <- par[i]
    z <- (x - mu)^2 / s2
    sum_z <- sum(z)
  }

  logist.alpha  <- 1 / (1 + exp(-alpha)) # scalar
  logist.nalpha <- 1 / (1 + exp(alpha))

  logist.beta   <- 1 / (1 + s2 * exp(-beta)) # scalar or vector
  logist.nbeta  <- 1 / (1 + exp(beta) / s2)

  y <- 0.5 * (z * logist.beta + log(logist.nbeta)) # vector

  # Negative log likelihood.
  C <- pmax(y, alpha)
  nllik <- -n0 * log(logist.alpha) - (n1 + n2) * (log(logist.nalpha))
  nllik <- nllik + 0.5 * (n1 * beta + sum1 * exp(-beta) + sum_z)
  nllik <- nllik - sum(log(exp(y - C) + exp(alpha - C)) + C)

  if (!calc_grad) {
    return(nllik)
  }

  dlogist.alpha <- logist.alpha * logist.nalpha
  dlogist.beta  <- logist.beta * logist.nbeta

  logist.y  <- 1 / (1 + exp(alpha - y)) # vector
  logist.ny <- 1 / (1 + exp(y - alpha))
  dlogist.y <- logist.y * logist.ny

  # Gradient.
  grad <- numeric(length(par))
  i <- 1
  if (!fix_pi0) {
    grad[i] <- -n0 * logist.nalpha + (n1 + n2) * logist.alpha - sum(logist.ny)
    i <- i + 1
  }
  if (!fix_a) {
    dy.dbeta <- 0.5 * (z * dlogist.beta - logist.beta)
    grad[i] <- 0.5 * (n1 - sum1 * exp(-beta)) - sum(logist.y * dy.dbeta)
    i <- i + 1
  }
  if (!fix_mu) {
    dy.dmu <- (mu - x) * logist.beta / s2
    grad[i] <- sum((mu - x) / s2) - sum(logist.y * dy.dmu)
  }
  attr(nllik, "gradient") <- grad

  if (!calc_hess) {
    return(nllik)
  }

  # Hessian.
  hess <- matrix(nrow = length(par), ncol = length(par))
  i <- 1
  if (!fix_pi0) {
    tmp <- (n0 + n1 + n2) * dlogist.alpha
    hess[i, i] <- tmp - sum(dlogist.y)
    j <- i + 1
    if (!fix_a) {
      hess[i, j] <- hess[j, i] <- sum(dlogist.y * dy.dbeta)
      j <- j + 1
    }
    if (!fix_mu) {
      hess[i, j] <- hess[j, i] <- sum(dlogist.y * dy.dmu)
    }
    i <- i + 1
  }
  if (!fix_a) {
    d2y.dbeta2 <- 0.5 * ((z * (logist.nbeta - logist.beta) - 1) * dlogist.beta)
    tmp <- 0.5 * sum1 * exp(-beta) - sum(dlogist.y * dy.dbeta^2)
    hess[i, i] <- tmp - sum(logist.y * d2y.dbeta2)
    j <- i + 1
    if (!fix_mu) {
      d2y.dbetadmu <- (mu - x) * dlogist.beta / s2
      tmp <- -sum(dlogist.y * dy.dbeta * dy.dmu)
      hess[i, j] <- hess[j, i] <- tmp - sum(logist.y * d2y.dbetadmu)
    }
    i <- i + 1
  }
  if (!fix_mu) {
    tmp <- sum(1 / s2 - dlogist.y * dy.dmu^2)
    hess[i, i] <- tmp - sum(logist.y * logist.beta / s2)
  }
  attr(nllik, "hessian") <- hess

  return(nllik)
}

test_n <- function(n, seed = 666, mb_times = 100L) {
  set.seed(seed)
  # true g is 0.5 delta_0 + 0.5 N(0, 2^2)
  theta <- c(rep(0, n), rnorm(n, sd = 2))
  s <- sqrt(rexp(2 * n))
  x <- theta + rnorm(2 * n, sd = s)

  test_res <- microbenchmark(ebnm_pn(x, s, "nlm"),
                             ebnm_pn(x, s, "nlm_nograd"),
                             ebnm_pn(x, s, "lbfgsb"),
                             ebnm_pn(x, s, "lbfgsb_wgrad"),
                             ebnm_pn(x, s, "trust"),
                             times = mb_times)

  return(test_res)
}
```

## n = 1000
```{r n1000}
test_n(1000)
```

## n = 10000
```{r n10000}
test_n(10000)
```

## n = 100000
```{r n100000}
test_n(100000, mb_times = 10L)
```
